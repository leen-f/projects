{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qyci018doXei",
    "outputId": "fb0fd2f2-1b78-4437-84e2-e66e6f2ac636"
   },
   "outputs": [],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iG0c2xtUpYY8",
    "outputId": "520235c7-f4bb-40dc-a9cf-742f5be6a4ac"
   },
   "outputs": [],
   "source": [
    "!pip install whoosh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wq-JZ8-ApYiO",
    "outputId": "5d8338c2-ecc8-4af8-c07b-38e0bf4188fb"
   },
   "outputs": [],
   "source": [
    "!pip install spellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FeGK25itpYoL",
    "outputId": "7407379c-7901-4d7c-cdaa-900ad51e2aac"
   },
   "outputs": [],
   "source": [
    "!pip install flashtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ukAIeNppqVW",
    "outputId": "8fd11829-1220-44d8-a5c3-c3ffcb371380"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qMXnvfsmptvx",
    "outputId": "851bf561-c777-4082-967f-63e4c7d18e8e"
   },
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VWgpCGq7Gzsd",
    "outputId": "84e7ac90-f4ed-42be-bf56-60b0e7dd6f41"
   },
   "outputs": [],
   "source": [
    "!pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v6C0L8yMpxpP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from spellchecker import SpellChecker\n",
    "from whoosh import index\n",
    "from whoosh import scoring\n",
    "from whoosh.query import Phrase\n",
    "from whoosh.analysis import StemmingAnalyzer\n",
    "from whoosh.index import create_in, open_dir\n",
    "from whoosh.fields import Schema, TEXT, ID\n",
    "from whoosh.qparser import MultifieldParser, PhrasePlugin, FuzzyTermPlugin, QueryParser, OrGroup\n",
    "from transformers import pipeline\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from math import log\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FjMAH9OZsw1f",
    "outputId": "fded70a9-8011-4bd4-f1d4-60596b87b7a5"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o3oDjdsss0W7",
    "outputId": "627cc225-1f9c-4def-e004-31725c08f49b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline(\"text2text-generation\", model=\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W9auG2ISEweT"
   },
   "outputs": [],
   "source": [
    "analyzer = StemmingAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3P41nhTGE1Oo"
   },
   "outputs": [],
   "source": [
    "schema = Schema(\n",
    "    title=TEXT(stored=True, analyzer=analyzer),\n",
    "    link=TEXT(stored=True),\n",
    "    content=TEXT(stored=True, analyzer=analyzer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yphw0x-YTHD7"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = word_tokenize(text)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return \" \".join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7c61jtT20Hel"
   },
   "source": [
    "# **####DOCUMENTS######**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KY7tfAk_5CsR"
   },
   "outputs": [],
   "source": [
    "index_dir = \"indexdir\"\n",
    "\n",
    "if os.path.exists(index_dir):\n",
    "    shutil.rmtree(index_dir)\n",
    "\n",
    "urls = [\n",
    "    \"https://en.wikipedia.org/wiki/Artificial_intelligence\",\n",
    "    \"https://en.wikipedia.org/wiki/Artificial_intelligence_in_video_games\",\n",
    "    \"https://en.wikipedia.org/wiki/Artificial_intelligence_in_healthcare\",\n",
    "    \"https://en.wikipedia.org/wiki/Artificial_intelligence_arms_race\",\n",
    "    \"https://en.wikipedia.org/wiki/Generative_artificial_intelligence\",\n",
    "    \"https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence\",\n",
    "    \"https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning\",\n",
    "    \"https://en.wikipedia.org/wiki/Natural_language_processing\",\n",
    "    \"https://en.wikipedia.org/wiki/Robotics\",\n",
    "    \"https://en.wikipedia.org/wiki/AI_safety\",\n",
    "    \"https://en.wikipedia.org/wiki/Cloud_computing\",\n",
    "    \"https://en.wikipedia.org/wiki/Cloud-native_computing\",\n",
    "    \"https://en.wikipedia.org/wiki/Cloud_computing_security\",\n",
    "    \"https://en.wikipedia.org/wiki/History_of_cloud_computing\",\n",
    "    \"https://en.wikipedia.org/wiki/Cloud_computing_research\",\n",
    "    \"https://en.wikipedia.org/wiki/Cloud-computing_comparison\",\n",
    "    \"https://en.wikipedia.org/wiki/Bioinformatics\",\n",
    "    \"https://en.wikipedia.org/wiki/Bioinformatics_discovery_of_non-coding_RNAs\",\n",
    "    \"https://en.wikipedia.org/wiki/Structural_bioinformatics\",\n",
    "    \"https://en.wikipedia.org/wiki/Data_mining\",\n",
    "    \"https://en.wikipedia.org/wiki/Educational_data_mining\",\n",
    "    \"https://en.wikipedia.org/wiki/Data_stream_mining\",\n",
    "    \"https://en.wikipedia.org/wiki/Relational_data_mining\",\n",
    "    \"https://en.wikipedia.org/wiki/Text_mining\",\n",
    "    \"https://en.wikipedia.org/wiki/Big_data\",\n",
    "    \"https://en.wikipedia.org/wiki/Big_data_ethics\",\n",
    "    \"https://en.wikipedia.org/wiki/Big_data_maturity_model\",\n",
    "    \"https://en.wikipedia.org/wiki/Big_Data_Scoring\",\n",
    "    \"https://en.wikipedia.org/wiki/Machine_learning\",\n",
    "    \"https://en.wikipedia.org/wiki/Neural_network_(machine_learning)\",\n",
    "    \"https://en.wikipedia.org/wiki/Active_learning_(machine_learning)\",\n",
    "    \"https://en.wikipedia.org/wiki/Quantum_machine_learning\",\n",
    "    \"https://en.wikipedia.org/wiki/Feature_(machine_learning)\",\n",
    "    \"https://en.wikipedia.org/wiki/Automated_machine_learning\",\n",
    "    \"https://en.wikipedia.org/wiki/Boosting_(machine_learning)\",\n",
    "    \"https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)\",\n",
    "    \"https://en.wikipedia.org/wiki/Machine_learning_in_bioinformatics\",\n",
    "    \"https://en.wikipedia.org/wiki/Reinforcement_learning\",\n",
    "    \"https://en.wikipedia.org/wiki/Data_science\",\n",
    "    \"https://en.wikipedia.org/wiki/Data_analysis\",\n",
    "    \"https://en.wikipedia.org/wiki/Social_data_science\",\n",
    "    \"https://en.wikipedia.org/wiki/Data_engineering\",\n",
    "    \"https://en.wikipedia.org/wiki/Data_Science_and_Predictive_Analytics\",\n",
    "    \"https://en.wikipedia.org/wiki/Predictive_analytics\",\n",
    "    \"https://en.wikipedia.org/wiki/Learning_analytics\",\n",
    "    \"https://en.wikipedia.org/wiki/Cybersecurity_engineering\",\n",
    "    \"https://en.wikipedia.org/wiki/Cyber-security_regulation\",\n",
    "    \"https://en.wikipedia.org/wiki/Information_security_standards\",\n",
    "    \"https://en.wikipedia.org/wiki/Network_security\",\n",
    "    \"https://en.wikipedia.org/wiki/National_Cyber_Security_Awareness_Month\"\n",
    "]\n",
    "\n",
    "def fetch_content(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        content = soup.get_text()\n",
    "        return content\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch content from {url}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "index_dir = \"indexdir\"\n",
    "\n",
    "if not os.path.exists(index_dir):\n",
    "    os.mkdir(index_dir)\n",
    "    ix = create_in(index_dir, schema)\n",
    "else:\n",
    "    ix = open_dir(index_dir)\n",
    "\n",
    "articles = [\n",
    "    {\"title\": \"Artificial Intelligence\", \"link\": \"https://en.wikipedia.org/wiki/Artificial_intelligence\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Artificial_intelligence\")},\n",
    "    {\"title\": \"Artificial Intelligence in Video Games\", \"link\": \"https://en.wikipedia.org/wiki/Artificial_intelligence_in_video_games\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Artificial_intelligence_in_video_games\")},\n",
    "    {\"title\": \"Artificial Intelligence in Healthcare\", \"link\": \"https://en.wikipedia.org/wiki/Artificial_intelligence_in_healthcare\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Artificial_intelligence_in_healthcare\")},\n",
    "    {\"title\": \"Artificial Intelligence Arms Race\", \"link\": \"https://en.wikipedia.org/wiki/Artificial_intelligence_arms_race\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Artificial_intelligence_arms_race\")},\n",
    "    {\"title\": \"Generative Artificial Intelligence\", \"link\": \"https://en.wikipedia.org/wiki/Generative_artificial_intelligence\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Generative_artificial_intelligence\")},\n",
    "    {\"title\": \"Ethics of Artificial Intelligence\", \"link\": \"https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence\")},\n",
    "    {\"title\": \"Knowledge Representation and Reasoning\", \"link\": \"https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning\")},\n",
    "    {\"title\": \"Natural Language Processing\", \"link\": \"https://en.wikipedia.org/wiki/Natural_language_processing\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Natural_language_processing\")},\n",
    "    {\"title\": \"Robotics\", \"link\": \"https://en.wikipedia.org/wiki/Robotics\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Robotics\")},\n",
    "    {\"title\": \"AI Safety\", \"link\": \"https://en.wikipedia.org/wiki/AI_safety\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/AI_safety\")},\n",
    "    {\"title\": \"Cloud Computing\", \"link\": \"https://en.wikipedia.org/wiki/Cloud_computing\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Cloud_computing\")},\n",
    "    {\"title\": \"Cloud-Native Computing\", \"link\": \"https://en.wikipedia.org/wiki/Cloud-native_computing\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Cloud-native_computing\")},\n",
    "    {\"title\": \"Cloud Computing Security\", \"link\": \"https://en.wikipedia.org/wiki/Cloud_computing_security\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Cloud_computing_security\")},\n",
    "    {\"title\": \"History of Cloud Computing\", \"link\": \"https://en.wikipedia.org/wiki/History_of_cloud_computing\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/History_of_cloud_computing\")},\n",
    "    {\"title\": \"Cloud Computing Research\", \"link\": \"https://en.wikipedia.org/wiki/Cloud_computing_research\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Cloud_computing_research\")},\n",
    "    {\"title\": \"Cloud Computing Comparison\", \"link\": \"https://en.wikipedia.org/wiki/Cloud-computing_comparison\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Cloud-computing_comparison\")},\n",
    "    {\"title\": \"Bioinformatics\", \"link\": \"https://en.wikipedia.org/wiki/Bioinformatics\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Bioinformatics\")},\n",
    "    {\"title\": \"Bioinformatics Discovery of Non-coding RNAs\", \"link\": \"https://en.wikipedia.org/wiki/Bioinformatics_discovery_of_non-coding_RNAs\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Bioinformatics_discovery_of_non-coding_RNAs\")},\n",
    "    {\"title\": \"Structural Bioinformatics\", \"link\": \"https://en.wikipedia.org/wiki/Structural_bioinformatics\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Structural_bioinformatics\")},\n",
    "    {\"title\": \"Data Mining\", \"link\": \"https://en.wikipedia.org/wiki/Data_mining\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Data_mining\")},\n",
    "    {\"title\": \"Educational Data Mining\", \"link\": \"https://en.wikipedia.org/wiki/Educational_data_mining\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Educational_data_mining\")},\n",
    "    {\"title\": \"Data Stream Mining\", \"link\": \"https://en.wikipedia.org/wiki/Data_stream_mining\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Data_stream_mining\")},\n",
    "    {\"title\": \"Relational Data Mining\", \"link\": \"https://en.wikipedia.org/wiki/Relational_data_mining\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Relational_data_mining\")},\n",
    "    {\"title\": \"Text Mining\", \"link\": \"https://en.wikipedia.org/wiki/Text_mining\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Text_mining\")},\n",
    "    {\"title\": \"Big Data\", \"link\": \"https://en.wikipedia.org/wiki/Big_data\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Big_data\")},\n",
    "    {\"title\": \"Big Data Ethics\", \"link\": \"https://en.wikipedia.org/wiki/Big_data_ethics\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Big_data_ethics\")},\n",
    "    {\"title\": \"Big Data Maturity Model\", \"link\": \"https://en.wikipedia.org/wiki/Big_data_maturity_model\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Big_data_maturity_model\")},\n",
    "    {\"title\": \"Big Data Scoring\", \"link\": \"https://en.wikipedia.org/wiki/Big_Data_Scoring\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Big_Data_Scoring\")},\n",
    "    {\"title\": \"Machine Learning\", \"link\": \"https://en.wikipedia.org/wiki/Machine_learning\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Machine_learning\")},\n",
    "    {\"title\": \"Neural Network (Machine Learning)\", \"link\": \"https://en.wikipedia.org/wiki/Neural_network_(machine_learning)\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Neural_network_(machine_learning)\")},\n",
    "    {\"title\": \"Active Learning (Machine Learning)\", \"link\": \"https://en.wikipedia.org/wiki/Active_learning_(machine_learning)\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Active_learning_(machine_learning)\")},\n",
    "    {\"title\": \"Quantum Machine Learning\", \"link\": \"https://en.wikipedia.org/wiki/Quantum_machine_learning\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Quantum_machine_learning\")},\n",
    "    {\"title\": \"Feature (Machine Learning)\", \"link\": \"https://en.wikipedia.org/wiki/Feature_(machine_learning)\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Feature_(machine_learning)\")},\n",
    "    {\"title\": \"Automated Machine Learning\", \"link\": \"https://en.wikipedia.org/wiki/Automated_machine_learning\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Automated_machine_learning\")},\n",
    "    {\"title\": \"Boosting (Machine Learning)\", \"link\": \"https://en.wikipedia.org/wiki/Boosting_(machine_learning)\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Boosting_(machine_learning)\")},\n",
    "    {\"title\": \"Transformer (Deep Learning Architecture)\", \"link\": \"https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)\")},\n",
    "    {\"title\": \"Machine Learning in Bioinformatics\", \"link\": \"https://en.wikipedia.org/wiki/Machine_learning_in_bioinformatics\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Machine_learning_in_bioinformatics\")},\n",
    "    {\"title\": \"Reinforcement Learning\", \"link\": \"https://en.wikipedia.org/wiki/Reinforcement_learning\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Reinforcement_learning\")},\n",
    "    {\"title\": \"Data Science\", \"link\": \"https://en.wikipedia.org/wiki/Data_science\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Data_science\")},\n",
    "    {\"title\": \"Data Analysis\", \"link\": \"https://en.wikipedia.org/wiki/Data_analysis\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Data_analysis\")},\n",
    "    {\"title\": \"Social Data Science\", \"link\": \"https://en.wikipedia.org/wiki/Social_data_science\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Social_data_science\")},\n",
    "    {\"title\": \"Data Engineering\", \"link\": \"https://en.wikipedia.org/wiki/Data_engineering\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Data_engineering\")},\n",
    "    {\"title\": \"Data Science and Predictive Analytics\", \"link\": \"https://en.wikipedia.org/wiki/Data_Science_and_Predictive_Analytics\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Data_Science_and_Predictive_Analytics\")},\n",
    "    {\"title\": \"Predictive Analytics\", \"link\": \"https://en.wikipedia.org/wiki/Predictive_analytics\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Predictive_analytics\")},\n",
    "    {\"title\": \"Learning Analytics\", \"link\": \"https://en.wikipedia.org/wiki/Learning_analytics\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Learning_analytics\")},\n",
    "    {\"title\": \"Cybersecurity Engineering\", \"link\": \"https://en.wikipedia.org/wiki/Cybersecurity_engineering\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Cybersecurity_engineering\")},\n",
    "    {\"title\": \"Cyber Security Regulation\", \"link\": \"https://en.wikipedia.org/wiki/Cyber-security_regulation\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Cyber-security_regulation\")},\n",
    "    {\"title\": \"Information Security Standards\", \"link\": \"https://en.wikipedia.org/wiki/Information_security_standards\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Information_security_standards\")},\n",
    "    {\"title\": \"Network Security\", \"link\": \"https://en.wikipedia.org/wiki/Network_security\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/Network_security\")},\n",
    "    {\"title\": \"National Cyber Security Awareness Month\", \"link\": \"https://en.wikipedia.org/wiki/National_Cyber_Security_Awareness_Month\", \"content\": fetch_content(\"https://en.wikipedia.org/wiki/National_Cyber_Security_Awareness_Month\")},\n",
    "]\n",
    "\n",
    "writer = ix.writer()\n",
    "\n",
    "seen_urls = set()\n",
    "for article in articles:\n",
    "    if article[\"link\"] not in seen_urls:\n",
    "        seen_urls.add(article[\"link\"])\n",
    "        title = preprocess_text(article[\"link\"])\n",
    "        content = preprocess_text(article[\"content\"])\n",
    "\n",
    "        writer.add_document(title=article[\"title\"], link=article[\"link\"], content=article[\"content\"])\n",
    "\n",
    "writer.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FwY2Y0Zt8q7y"
   },
   "source": [
    "# #########BM25##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "id": "FJGX8IhI5qD3",
    "outputId": "d55107e4-4d5f-4cc5-9a1a-d126060faf72"
   },
   "outputs": [],
   "source": [
    "def expand_abbreviations(query):\n",
    "    query = query.lower()\n",
    "    abbreviations = {\"ai\": \"artificial intelligence\",\n",
    "                     \"ml\": \"machine learning\",\n",
    "                     \"nlp\": \"natural language processing\",\n",
    "                     \"iot\": \"internet of things\",\n",
    "                     \"NASA\": \"national aeronautics and space administration\",\n",
    "                     \"etc\": \"et cetera\",\n",
    "                     \"i.e.\": \"that is\",\n",
    "                     \"e.g.\": \"for example\"\n",
    "                     }\n",
    "    for abbr, full_form in abbreviations.items():\n",
    "        query = query.replace(abbr.lower(), full_form.lower())\n",
    "    return query\n",
    "\n",
    "def correct_spelling(query):\n",
    "    query = query.lower()\n",
    "    spell = SpellChecker()\n",
    "    words = query.split()\n",
    "    corrected_words = []\n",
    "\n",
    "    for word in words:\n",
    "        corrected_word = spell.correction(word)\n",
    "        corrected_words.append(corrected_word)\n",
    "\n",
    "    corrected_query = \" \".join(corrected_words)\n",
    "    return corrected_query\n",
    "\n",
    "def remove_stop_words(query):\n",
    "    query = query.lower()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    word_tokens = word_tokenize(query)\n",
    "    filtered_query = [w for w in word_tokens if w not in stop_words]\n",
    "    return \" \".join(filtered_query)\n",
    "\n",
    "def retrieve_articles(query, exact_phrase=None):\n",
    "    results = []\n",
    "\n",
    "    if not os.path.exists(\"indexdir\"):\n",
    "        print(\"Index directory does not exist!\")\n",
    "        return results\n",
    "\n",
    "    index = open_dir(\"indexdir\")\n",
    "\n",
    "    corr_query = correct_spelling(query)\n",
    "    corr_exp_query = expand_abbreviations(corr_query)\n",
    "    no_stop_query = remove_stop_words(corr_exp_query)\n",
    "    final_query = preprocess_text(no_stop_query)\n",
    "    exact_phrase = preprocess_text(exact_phrase) if exact_phrase else None\n",
    "\n",
    "    with index.searcher(weighting=scoring.BM25F()) as searcher:\n",
    "        print(f\"Number of documents in index: {searcher.doc_count()}\")\n",
    "\n",
    "        parser = MultifieldParser([\"title\", \"content\"], schema=index.schema, group=OrGroup)\n",
    "\n",
    "        try:\n",
    "            if exact_phrase:\n",
    "                words = exact_phrase.split()\n",
    "                query_obj = Phrase(\"content\", words)\n",
    "            else:\n",
    "                query_obj = parser.parse(query)\n",
    "\n",
    "            hits = searcher.search(query_obj, limit=10)\n",
    "\n",
    "            for hit in hits:\n",
    "                results.append({\n",
    "                    \"title\": hit[\"title\"],\n",
    "                    \"link\": hit[\"link\"],\n",
    "                    \"score\": hit.score\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during search: {e}\")\n",
    "\n",
    "    return results[:5]\n",
    "\n",
    "def search_query(query):\n",
    "    query = query.lower()\n",
    "    exact_phrase = None\n",
    "\n",
    "    if '\"' in query:\n",
    "        match = re.search(r'\"(.*?)\"', query)\n",
    "        if match:\n",
    "            exact_phrase = match.group(1)\n",
    "            query = query.replace(match.group(0), '').strip()\n",
    "    clean_q = remove_stop_words(query)\n",
    "    print(\"clean: \", clean_q)\n",
    "    clean_exp = expand_abbreviations(clean_q)\n",
    "    print(\"clean expanded: \", clean_exp)\n",
    "    clean_exp_corrected_q = correct_spelling(clean_exp)\n",
    "    print(\"clean expanded corrected: \", clean_exp_corrected_q)\n",
    "    final_query = apply_lemmatization(clean_exp_corrected_q)\n",
    "    print(\"final: \", final_query)\n",
    "\n",
    "    results = retrieve_articles(final_query, exact_phrase=exact_phrase)\n",
    "\n",
    "    if results:\n",
    "        return \"\\n\\n\".join([f\"{res['title']}: {res['link']})\" for res in results])\n",
    "    else:\n",
    "        return \"No results found.\"\n",
    "\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=search_query,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    title=\"Information Retrieval System\",\n",
    "    description=\"Enter a query to retrieve relevant articles.\"\n",
    ")\n",
    "\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF and COSINE##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_abbreviations(query):\n",
    "    abbreviations = {\"ai\": \"artificial intelligence\",\n",
    "                     \"ml\": \"machine learning\",\n",
    "                     \"nlp\": \"natural language processing\",\n",
    "                     \"iot\": \"internet of things\",\n",
    "                     \"NASA\": \"national aeronautics and space administration\",\n",
    "                     \"etc\": \"et cetera\",\n",
    "                     \"i.e.\": \"that is\",\n",
    "                     \"e.g.\": \"for example\"\n",
    "                     }\n",
    "    for abbr, full_form in abbreviations.items():\n",
    "        query = query.replace(abbr.lower(), full_form.lower())\n",
    "    return query\n",
    "\n",
    "def correct_spelling(query):\n",
    "    spell = SpellChecker()\n",
    "    words = query.split()\n",
    "    corrected_words = []\n",
    "\n",
    "    for word in words:\n",
    "        corrected_word = spell.correction(word)\n",
    "        corrected_words.append(corrected_word)\n",
    "\n",
    "    corrected_query = \" \".join(corrected_words)\n",
    "    return corrected_query\n",
    "\n",
    "def remove_stop_words(query):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    word_tokens = word_tokenize(query)\n",
    "    filtered_query = [w for w in word_tokens if w not in stop_words]\n",
    "    return \" \".join(filtered_query)\n",
    "\n",
    "def apply_lemmatization(query):\n",
    "    query = query.lower()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = word_tokenize(query)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return \" \".join(lemmatized_words)\n",
    "\n",
    "def retrieve_articles(query, exact_phrase=None):\n",
    "    results = []\n",
    "\n",
    "    if not os.path.exists(\"indexdir\"):\n",
    "        print(\"Index directory does not exist!\")\n",
    "        return results\n",
    "\n",
    "    index = open_dir(\"indexdir\")\n",
    "    query = query.lower()\n",
    "\n",
    "    with index.searcher() as searcher:\n",
    "        print(f\"Number of documents in index: {searcher.doc_count()}\")\n",
    "\n",
    "        parser = MultifieldParser([\"title\", \"content\"], schema=index.schema)\n",
    "\n",
    "        try:\n",
    "            if exact_phrase:\n",
    "                query_obj = parser.parse(f'(\"{exact_phrase}\" AND {query})')\n",
    "            else:\n",
    "                query_obj = parser.parse(query)\n",
    "\n",
    "            hits = searcher.search(query_obj, limit=10)\n",
    "\n",
    "            documents = [hit[\"content\"] for hit in hits]\n",
    "            titles = [hit[\"title\"] for hit in hits]\n",
    "            links = [hit[\"link\"] for hit in hits]\n",
    "\n",
    "            vectorizer = TfidfVectorizer()\n",
    "            tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "            query_vector = vectorizer.transform([query])\n",
    "\n",
    "            similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
    "\n",
    "            ranked_indices = np.argsort(similarities)[::-1]\n",
    "\n",
    "            for idx in ranked_indices[:5]:\n",
    "                results.append({\n",
    "                    \"title\": titles[idx],\n",
    "                    \"link\": links[idx],\n",
    "                    \"similarity\": similarities[idx]\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during search: {e}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def search_query(query):\n",
    "    exact_phrase = None\n",
    "    query = query.lower()\n",
    "    if '\"' in query:\n",
    "        match = re.search(r'\"(.*?)\"', query)\n",
    "        if match:\n",
    "            exact_phrase = match.group(1)\n",
    "            query = query.replace(match.group(0), '').strip()\n",
    "\n",
    "    clean_q = remove_stop_words(query)\n",
    "    print(\"clean: \", clean_q)\n",
    "    clean_exp = expand_abbreviations(clean_q)\n",
    "    print(\"clean expanded: \", clean_exp)\n",
    "    clean_exp_corrected_q = correct_spelling(clean_exp)\n",
    "    print(\"clean expanded corrected: \", clean_exp_corrected_q)\n",
    "    final_query = apply_lemmatization(clean_exp_corrected_q)\n",
    "    print(\"final: \", final_query)\n",
    "\n",
    "    results = retrieve_articles(final_query, exact_phrase=exact_phrase)\n",
    "\n",
    "    if results:\n",
    "        return \"\\n\\n\".join([f\"{res['title']}: {res['link']}\" for res in results])\n",
    "    else:\n",
    "        return \"No results found.\"\n",
    "\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=search_query,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    title=\"Information Retrieval System\",\n",
    "    description=\"Enter a query to retrieve relevant articles.\"\n",
    ")\n",
    "\n",
    "iface.launch()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
